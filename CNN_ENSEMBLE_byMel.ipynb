{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWnHXLPfZrA_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# classification"
      ],
      "metadata": {
        "id": "RubAPLKTQSaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import ResNet34_Weights\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "BRjqtoJfSAB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainset\n",
        "train_path = './SVD/mel_spectrograms/train'\n",
        "trainset = ImageFolder(root=train_path, transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                                     transforms.Resize((224, 224))]))\n",
        "#print(trainset)\n",
        "print(f'\\nclass : index\\n{trainset.class_to_idx}')"
      ],
      "metadata": {
        "id": "yCdp_2mJQa8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testset\n",
        "test_path = './SVD/mel_spectrograms/test'\n",
        "testset = ImageFolder(root=test_path, transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                                    transforms.Resize((224, 224))]))\n",
        "#print(testset)\n",
        "print(f'\\nclass : index\\n{testset.class_to_idx}')"
      ],
      "metadata": {
        "id": "QMA-Bb4hUQdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader\n",
        "train_dataloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=4)\n",
        "test_dataloader = DataLoader(testset, batch_size=4, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "2J2DFz-cTa9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')"
      ],
      "metadata": {
        "id": "BZNJZxw3WJOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet-pytorch"
      ],
      "metadata": {
        "id": "JIP7eV3FWROD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A model includes 20 effnet models\n",
        "# When test five times, the seed is 1000*n, 10000*n, not 100*n, so that the seed does not overlapfrom efficientnet_pytorch\n",
        "import EfficientNet\n",
        "for num in range(19,21):\n",
        "    # define model\n",
        "    pretrained_model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "    pretrained_model._fc = nn.Linear(1280, 2)\n",
        "    model = pretrained_model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "    # training\n",
        "    torch.manual_seed(num*100) #seeds be 100, 200, 300, 400, 500...\n",
        "    # model.train()\n",
        "    print(f'start train {num}th model. seed={num*100}')\n",
        "    for epoch in range(10): # epoch 10으로 설정\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_dataloader):\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:\n",
        "                print(f'[epoch: {epoch+1} / batch: {i+1:3d}] loss: {running_loss/100:.4f}')\n",
        "                running_loss = 0.0\n",
        "    print(f'Finished Training_{num}')\n",
        "    # model save\n",
        "    path = f'./SVD/model_mel-spec_{num}.pth'\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f'Model has saved as ./SVD/model_mel-spec_{num}.pth')\n",
        "    print('---------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "vCi8iAmyYAqG",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A function that load saved CNN models (effnet) and creates a list of prediction labels (cnn_preds).\n",
        "def CNN_pred(model, loader):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            y_true.extend(labels.tolist())\n",
        "            y_pred.extend(preds.tolist())\n",
        "    return [y_true, y_pred]\n",
        "\n",
        "# function get cm and return acc, f1\n",
        "def metrics(cm):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "    recall = (tp) / (tp + fn)\n",
        "    precision = (tp) / (tp + fp)\n",
        "    f1 = (2 * recall * precision) / (recall + precision)\n",
        "    return accuracy, f1"
      ],
      "metadata": {
        "id": "Dy0zbohHm1QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recalling previously stored models 1 to 20,\n",
        "# Since you have to average 1 to 20, put it in the form of a dictionary in cnn_preds.\n",
        "cnn_preds = {}\n",
        "for num in range(1,21):\n",
        "    pretrained_model = EfficientNet.from_name('efficientnet-b0')\n",
        "    pretrained_model._fc = nn.Linear(1280, 2)\n",
        "    state_dict = torch.load(f'./SVD/model_mel-spec_{num}.pth')\n",
        "    pretrained_model.load_state_dict(state_dict)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = pretrained_model.to(device)\n",
        "\n",
        "    y_true, cnn_pred = CNN_pred(model, test_dataloader)\n",
        "    # Store the predicted value in a dictionary with keys such as 'cnn_pred_1', 'cnn_pred_2', etc\n",
        "    cnn_preds[f'cnn_pred_{num}'] = cnn_pred\n",
        "\n",
        "\n",
        "print(y_true) # testset\n",
        "print(cnn_preds) # dictionary that has 20 predictions."
      ],
      "metadata": {
        "collapsed": true,
        "id": "4hKNOHkjq5ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Applicated HardVoting implementation"
      ],
      "metadata": {
        "id": "8WJjgGj2t4-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for n in range(1,21):\n",
        "    y_preds = np.vstack(list(cnn_preds4.values())[:n]) # Since it may not be good to mix a lot of models unconditionally, I checked from 1 to n for confirmation.\n",
        "    y_pred_avg = np.mean(y_preds, axis=0)\n",
        "    # Determining the final prediction class based on the average probability (binary classification based on 0.3, 0.4, 0.5, etc.)\n",
        "    # Combine dictionaries to create a single prediction label\n",
        "    # Determining the final prediction based on the average of the predictions (means greater than 0.45 => 1)\n",
        "    y_pred_final = (y_pred_avg > 0.45).astype(int)\n",
        "    cm = confusion_matrix(y_true, y_pred_final)\n",
        "    print(f'Voting Case : by combine 1~{n}models :')\n",
        "    print(cm)\n",
        "    accuracy, f1 = metrics(cm)\n",
        "    print(accuracy, f1)\n",
        "    print('--------------------------------------------------')"
      ],
      "metadata": {
        "id": "Bu3wejfIt-I6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}